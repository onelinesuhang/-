

# 半监督学习

### 13.1 未标记样本

让学习器不依赖外界交互、自动地利用未标记样本来提升学习性能，就是半监督学习（semi-supervised learning）

最常用的是“聚类假设”即假设数据存在簇结构，同一个簇的样本属于同一个类别。

半监督学习中另外一种常见的假设是流行假设，即假设数据分布在一个流形结构上，邻近样本拥有相似的输出值。

以上两种假设，其本质都是“相似的样本拥有相似的输出”

半监督学习可以划分为纯半监督和直推学习，前者假定训练数据中的未标记样本并非待预测数据，后者假定学习过程中所考虑的未标记样本恰是待预测数据，学习的目的就是在这些未标记样本上获得最优泛化性能。

### 13.2 生成式方法

生成式方法是直接基于生成式模型的方法，此类方法假设所有数据（无论有无标记）都是由同一个潜在的模型“生成”的。这个假设使我们能够通过潜在模型的参数将未标记数据与学习目标联系起来，而未标记数据的标记则可看做模型的缺失参数，通常可基于EM算法进行极大似然估计

**假设样本由高斯混合模型生成，且每个类别对应一个高斯混合成分**





![1564553426653](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564553426653.png)



数据样本概率密度函数加入高斯混合成分的参数

![1564553547702](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564553547702.png)

先验概率 P(y=yi) 就是alpha

![1564553603158](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564553603158.png)

公式13.2推导

![1564553745970](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564553745970.png)

![1564553860085](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564553860085.png)

如果已知x由那个高斯混合成分生成，就知道了其类别

![1564554838848](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564554838848.png)

公式第1项是针对有标记样本进行的最大似然估计，第二项直接运用的13.1式，因为不知道标记类型，它可能是N个高斯混合模型中的任何一个。

直观上来看，**基于半监督的高斯混合模型有机地整合了贝叶斯分类器与高斯混合聚类的核心思想**，有效地利用了未标记样本数据隐含的分布信息，从而使得参数的估计更加准确。

EM方法进行求解：

首先对各个高斯混合成分的参数及混合系数进行初始化，计算出各个PM（即γji，第i个样本属于j类，有标记样本则直接属于特定类），再最大化似然函数（即LL（D）分别对α、u和∑求偏导 ），对参数进行迭代更新。

![1564555049755](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564555049755.png)

13.5式与13.1式类似

![1564555466539](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564555466539.png)

以上就是通过已经有标记的样本对初始的参数进行初始化

![1564556212643](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564556212643.png)

![1564556237899](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564556237899.png)

上式的推导在第9章 中有

![1564560292804](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564560292804.png)

![1564560461645](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564560461645.png)

![1564560557941](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564560557941.png)

xj是未标记样本，li表示第i类的有标记样本数，所有两者不冲突，对于没有标记的样本，i的都是常数，这也是为什么ui能够提出来的原因

13.7的求解过程类似，在这不再搬运

13.8利用拉格朗日形式进行求解

![1564561629131](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564561629131.png)

![1564561714295](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564561714295.png)

![1564561952158](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564561952158.png)

![1564562060608](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564562060608.png)

![1564562162437](C:\Users\sdjcs\AppData\Roaming\Typora\typora-user-images\1564562162437.png)



当参数迭代更新收敛后，对于待预测样本x，便可以像贝叶斯分类器那样计算出样本属于每个类簇的后验概率，接着找出概率最大的即可：

![5bc856e3dfb1c](C:\Users\sdjcs\Desktop\5bc856e3dfb1c.png)

看完这些，突然觉得很牛逼，但是模型假设必须准确，假设必须准确，这种在现实任务中很难实现。